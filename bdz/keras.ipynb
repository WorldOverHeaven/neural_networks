{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape=(2100, 20)\n",
      "test.shape=(210, 20)\n",
      "Using 210 samples for training and 2100 for validation\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"data/segmentation_target.test\")\n",
    "test = pd.read_csv(\"data/segmentation_target.data\")\n",
    "\n",
    "print(f\"{train.shape=}\")\n",
    "print(f\"{test.shape=}\")\n",
    "\n",
    "val_dataframe = train.sample(frac=1)\n",
    "train_dataframe = test.sample(frac=1)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn' has no attribute 'preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[79], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43msklearn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocessing\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'sklearn' has no attribute 'preprocessing'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4' '1' '0' '3' '6']\n",
      "FOLIAGE      4\n",
      "PATH         1\n",
      "GRASS        0\n",
      "CEMENT       3\n",
      "BRICKFACE    6\n",
      "            ..\n",
      "FOLIAGE      4\n",
      "WINDOW       2\n",
      "BRICKFACE    6\n",
      "FOLIAGE      4\n",
      "BRICKFACE    6\n",
      "Name: TARGET, Length: 210, dtype: object\n",
      "labels.shape=(210,)\n",
      "['2' '6' '2' '0' '4']\n",
      "WINDOW       2\n",
      "BRICKFACE    6\n",
      "WINDOW       2\n",
      "GRASS        0\n",
      "FOLIAGE      4\n",
      "            ..\n",
      "SKY          5\n",
      "BRICKFACE    6\n",
      "FOLIAGE      4\n",
      "PATH         1\n",
      "GRASS        0\n",
      "Name: TARGET, Length: 2100, dtype: object\n",
      "labels.shape=(2100,)\n"
     ]
    }
   ],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    dataframe[\"TARGET\"] = dataframe[\"TARGET\"].apply(lambda a: str(a))\n",
    "    print(dataframe[\"TARGET\"].values[:5])\n",
    "    labels = dataframe.pop(\"TARGET\")\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'REGION-CENTROID-COL': <tf.Tensor: shape=(), dtype=float64, numpy=121.0>, 'REGION-CENTROID-ROW': <tf.Tensor: shape=(), dtype=float64, numpy=113.0>, 'REGION-PIXEL-COUNT': <tf.Tensor: shape=(), dtype=int64, numpy=9>, 'SHORT-LINE-DENSITY-5': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>, 'SHORT-LINE-DENSITY-2': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>, 'VEDGE-MEAN': <tf.Tensor: shape=(), dtype=float64, numpy=1.722222>, 'VEDGE-SD': <tf.Tensor: shape=(), dtype=float64, numpy=1.5296303>, 'HEDGE-MEAN': <tf.Tensor: shape=(), dtype=float64, numpy=2.944444>, 'HEDGE-SD': <tf.Tensor: shape=(), dtype=float64, numpy=1.5296295>, 'INTENSITY-MEAN': <tf.Tensor: shape=(), dtype=float64, numpy=20.25926>, 'RAWRED-MEAN': <tf.Tensor: shape=(), dtype=float64, numpy=20.0>, 'RAWBLUE-MEAN': <tf.Tensor: shape=(), dtype=float64, numpy=25.444445>, 'RAWGREEN-MEAN': <tf.Tensor: shape=(), dtype=float64, numpy=15.333333>, 'EXRED-MEAN': <tf.Tensor: shape=(), dtype=float64, numpy=-0.7777778>, 'EXBLUE-MEAN': <tf.Tensor: shape=(), dtype=float64, numpy=15.555555>, 'EXGREEN-MEAN': <tf.Tensor: shape=(), dtype=float64, numpy=-14.777778>, 'VALUE-MEAN': <tf.Tensor: shape=(), dtype=float64, numpy=25.444445>, 'SATURATION-MEAN': <tf.Tensor: shape=(), dtype=float64, numpy=0.39658895>, 'HUE-MEAN': <tf.Tensor: shape=(), dtype=float64, numpy=-1.5856091>}\n",
      "\n",
      "\n",
      "Target: tf.Tensor(6, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"\\n\\nTarget:\", y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(21)\n",
    "val_ds = val_ds.batch(21)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "from keras.layers import Normalization\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "# Numerical features\n",
    "f1 = keras.Input(shape=(1,), name=\"REGION-CENTROID-COL\")\n",
    "f2 = keras.Input(shape=(1,), name=\"REGION-CENTROID-ROW\")\n",
    "f3 = keras.Input(shape=(1,), name=\"REGION-PIXEL-COUNT\")\n",
    "f4 = keras.Input(shape=(1,), name=\"SHORT-LINE-DENSITY-5\")\n",
    "f5 = keras.Input(shape=(1,), name=\"SHORT-LINE-DENSITY-2\")\n",
    "f6 = keras.Input(shape=(1,), name=\"VEDGE-MEAN\")\n",
    "f7 = keras.Input(shape=(1,), name=\"VEDGE-SD\")\n",
    "f8 = keras.Input(shape=(1,), name=\"HEDGE-MEAN\")\n",
    "f9 = keras.Input(shape=(1,), name=\"HEDGE-SD\")\n",
    "f10 = keras.Input(shape=(1,), name=\"INTENSITY-MEAN\")\n",
    "f11 = keras.Input(shape=(1,), name=\"RAWRED-MEAN\")\n",
    "f12 = keras.Input(shape=(1,), name=\"RAWBLUE-MEAN\")\n",
    "f13 = keras.Input(shape=(1,), name=\"RAWGREEN-MEAN\")\n",
    "f14 = keras.Input(shape=(1,), name=\"EXRED-MEAN\")\n",
    "f15 = keras.Input(shape=(1,), name=\"EXBLUE-MEAN\")\n",
    "f16 = keras.Input(shape=(1,), name=\"EXGREEN-MEAN\")\n",
    "f17 = keras.Input(shape=(1,), name=\"VALUE-MEAN\")\n",
    "f18 = keras.Input(shape=(1,), name=\"SATURATION-MEAN\")\n",
    "f19 = keras.Input(shape=(1,), name=\"HUE-MEAN\")\n",
    "\n",
    "all_inputs = [\n",
    "    f1,\n",
    "    f2,\n",
    "    f3,\n",
    "    f4,\n",
    "    f5,\n",
    "    f6,\n",
    "    f7,\n",
    "    f8,\n",
    "    f9,\n",
    "    f10,\n",
    "    f11,\n",
    "    f12,\n",
    "    f13,\n",
    "    f14,\n",
    "    f15,\n",
    "    f16,\n",
    "    f17,\n",
    "    f18,\n",
    "    f19,\n",
    "]\n",
    "\n",
    "f1_encoded = encode_numerical_feature(f1, \"REGION-CENTROID-COL\", train_ds)\n",
    "f2_encoded = encode_numerical_feature(f2, \"REGION-CENTROID-ROW\", train_ds)\n",
    "f3_encoded = encode_numerical_feature(f3, \"REGION-PIXEL-COUNT\", train_ds)\n",
    "f4_encoded = encode_numerical_feature(f4, \"SHORT-LINE-DENSITY-5\", train_ds)\n",
    "f5_encoded = encode_numerical_feature(f5, \"SHORT-LINE-DENSITY-2\", train_ds)\n",
    "f6_encoded = encode_numerical_feature(f6, \"VEDGE-MEAN\", train_ds)\n",
    "f7_encoded = encode_numerical_feature(f7, \"VEDGE-SD\", train_ds)\n",
    "f8_encoded = encode_numerical_feature(f8, \"HEDGE-MEAN\", train_ds)\n",
    "f9_encoded = encode_numerical_feature(f9, \"HEDGE-SD\", train_ds)\n",
    "f10_encoded = encode_numerical_feature(f10, \"INTENSITY-MEAN\", train_ds)\n",
    "f11_encoded = encode_numerical_feature(f11, \"RAWRED-MEAN\", train_ds)\n",
    "f12_encoded = encode_numerical_feature(f12, \"RAWBLUE-MEAN\", train_ds)\n",
    "f13_encoded = encode_numerical_feature(f13, \"RAWGREEN-MEAN\", train_ds)\n",
    "f14_encoded = encode_numerical_feature(f14, \"EXRED-MEAN\", train_ds)\n",
    "f15_encoded = encode_numerical_feature(f15, \"EXBLUE-MEAN\", train_ds)\n",
    "f16_encoded = encode_numerical_feature(f16, \"EXGREEN-MEAN\", train_ds)\n",
    "f17_encoded = encode_numerical_feature(f17, \"VALUE-MEAN\", train_ds)\n",
    "f18_encoded = encode_numerical_feature(f18, \"SATURATION-MEAN\", train_ds)\n",
    "f19_encoded = encode_numerical_feature(f19, \"HUE-MEAN\", train_ds)\n",
    "\n",
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        f1_encoded,\n",
    "        f2_encoded,\n",
    "        f3_encoded,\n",
    "        f4_encoded,\n",
    "        f5_encoded,\n",
    "        f6_encoded,\n",
    "        f7_encoded,\n",
    "        f8_encoded,\n",
    "        f9_encoded,\n",
    "        f10_encoded,\n",
    "        f11_encoded,\n",
    "        f12_encoded,\n",
    "        f13_encoded,\n",
    "        f14_encoded,\n",
    "        f15_encoded,\n",
    "        f16_encoded,\n",
    "        f17_encoded,\n",
    "        f18_encoded,\n",
    "        f19_encoded,\n",
    "    ]\n",
    ")\n",
    "\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", loss= tf.keras.losses.MeanSquaredError(), metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 7.9730 - accuracy: 0.2667 - val_loss: 7.8927 - val_accuracy: 0.2843\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 7.9296 - accuracy: 0.2714 - val_loss: 7.8909 - val_accuracy: 0.2843\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 7.9277 - accuracy: 0.2714 - val_loss: 7.8893 - val_accuracy: 0.2843\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9436 - accuracy: 0.2762 - val_loss: 7.8878 - val_accuracy: 0.2843\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9474 - accuracy: 0.2762 - val_loss: 7.8862 - val_accuracy: 0.2843\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9535 - accuracy: 0.2619 - val_loss: 7.8847 - val_accuracy: 0.2838\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9332 - accuracy: 0.2667 - val_loss: 7.8832 - val_accuracy: 0.2843\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9383 - accuracy: 0.2762 - val_loss: 7.8818 - val_accuracy: 0.2843\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9375 - accuracy: 0.2714 - val_loss: 7.8805 - val_accuracy: 0.2843\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9064 - accuracy: 0.2810 - val_loss: 7.8795 - val_accuracy: 0.2843\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 7.9314 - accuracy: 0.2762 - val_loss: 7.8785 - val_accuracy: 0.2843\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 7.9169 - accuracy: 0.2810 - val_loss: 7.8775 - val_accuracy: 0.2843\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 7.9235 - accuracy: 0.2714 - val_loss: 7.8767 - val_accuracy: 0.2843\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9323 - accuracy: 0.2714 - val_loss: 7.8759 - val_accuracy: 0.2843\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 7.9133 - accuracy: 0.2810 - val_loss: 7.8752 - val_accuracy: 0.2843\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 7.9050 - accuracy: 0.2714 - val_loss: 7.8745 - val_accuracy: 0.2843\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 7.9266 - accuracy: 0.2762 - val_loss: 7.8740 - val_accuracy: 0.2843\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 7.9213 - accuracy: 0.2762 - val_loss: 7.8734 - val_accuracy: 0.2843\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 7.9220 - accuracy: 0.2762 - val_loss: 7.8728 - val_accuracy: 0.2843\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9240 - accuracy: 0.2762 - val_loss: 7.8721 - val_accuracy: 0.2843\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9351 - accuracy: 0.2667 - val_loss: 7.8715 - val_accuracy: 0.2843\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9097 - accuracy: 0.2714 - val_loss: 7.8710 - val_accuracy: 0.2843\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 7.9023 - accuracy: 0.2762 - val_loss: 7.8705 - val_accuracy: 0.2843\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 7.9528 - accuracy: 0.2810 - val_loss: 7.8700 - val_accuracy: 0.2843\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9070 - accuracy: 0.2762 - val_loss: 7.8695 - val_accuracy: 0.2843\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9082 - accuracy: 0.2810 - val_loss: 7.8691 - val_accuracy: 0.2843\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9102 - accuracy: 0.2810 - val_loss: 7.8686 - val_accuracy: 0.2843\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.8985 - accuracy: 0.2810 - val_loss: 7.8682 - val_accuracy: 0.2843\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9286 - accuracy: 0.2857 - val_loss: 7.8679 - val_accuracy: 0.2843\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.8811 - accuracy: 0.2810 - val_loss: 7.8676 - val_accuracy: 0.2843\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.8820 - accuracy: 0.2762 - val_loss: 7.8673 - val_accuracy: 0.2843\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9001 - accuracy: 0.2857 - val_loss: 7.8670 - val_accuracy: 0.2843\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.8872 - accuracy: 0.2762 - val_loss: 7.8668 - val_accuracy: 0.2843\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.8894 - accuracy: 0.2762 - val_loss: 7.8665 - val_accuracy: 0.2843\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.8788 - accuracy: 0.2810 - val_loss: 7.8663 - val_accuracy: 0.2843\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.8869 - accuracy: 0.2810 - val_loss: 7.8661 - val_accuracy: 0.2843\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 7.8796 - accuracy: 0.2810 - val_loss: 7.8659 - val_accuracy: 0.2843\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.9023 - accuracy: 0.2762 - val_loss: 7.8656 - val_accuracy: 0.2843\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.8978 - accuracy: 0.2857 - val_loss: 7.8654 - val_accuracy: 0.2843\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 7.9114 - accuracy: 0.2714 - val_loss: 7.8652 - val_accuracy: 0.2843\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 7.9001 - accuracy: 0.2762 - val_loss: 7.8649 - val_accuracy: 0.2843\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.8883 - accuracy: 0.2762 - val_loss: 7.8647 - val_accuracy: 0.2843\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 7.8771 - accuracy: 0.2810 - val_loss: 7.8645 - val_accuracy: 0.2843\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s 28ms/step - loss: 7.8993 - accuracy: 0.2762 - val_loss: 7.8642 - val_accuracy: 0.2843\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 7.9048 - accuracy: 0.2810 - val_loss: 7.8640 - val_accuracy: 0.2843\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 7.8927 - accuracy: 0.2857 - val_loss: 7.8638 - val_accuracy: 0.2843\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 7.9113 - accuracy: 0.2810 - val_loss: 7.8635 - val_accuracy: 0.2843\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 7.8845 - accuracy: 0.2810 - val_loss: 7.8634 - val_accuracy: 0.2843\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 7.8937 - accuracy: 0.2857 - val_loss: 7.8632 - val_accuracy: 0.2843\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 7.8911 - accuracy: 0.2857 - val_loss: 7.8629 - val_accuracy: 0.2843\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x20b76f01990>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 185ms/step\n",
      "[[0.9965597 ]\n",
      " [0.9992046 ]\n",
      " [0.12387908]\n",
      " [0.9644068 ]\n",
      " [0.96538806]\n",
      " [0.99520004]\n",
      " [0.99712485]\n",
      " [0.99834263]\n",
      " [0.9866264 ]\n",
      " [0.97679627]\n",
      " [0.94994515]\n",
      " [0.99722564]\n",
      " [0.13252275]\n",
      " [0.9972764 ]\n",
      " [0.99631304]\n",
      " [0.9400719 ]\n",
      " [0.999343  ]\n",
      " [0.98563695]\n",
      " [0.97429013]\n",
      " [0.99939275]\n",
      " [0.9998081 ]]\n",
      "This particular patient had a 99.7 percent probability of having a heart disease, as evaluated by our model.\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(val_ds.take(1))\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "print(\n",
    "    \"This particular patient had a %.1f percent probability \"\n",
    "    \"of having a heart disease, as evaluated by our model.\" % (100 * predictions[0][0],)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
